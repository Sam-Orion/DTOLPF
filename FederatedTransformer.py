# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MNDU-K-8BF5qAgYSKLPivm-wDZqoRIvd
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler

df = pd.read_csv("hourly_load.csv")
df["datetime"] = pd.to_datetime(df["datetime"])
df = df.sort_values("datetime").reset_index(drop=True)

# 2. Split into Federated Clients
#=====================================================================
N_CLIENTS = 5
df["client_id"] = pd.qcut(df.index, q=N_CLIENTS, labels=[f"client_{i+1}" for i in range(N_CLIENTS)])

clients = {cid: df[df["client_id"] == cid].reset_index(drop=True)
           for cid in df["client_id"].unique()}

# 3. Build time-series windows for each client
#=====================================================================
def create_timeseries(data, window=24):
    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(data.reshape(-1, 1))

    X, y = [], []
    for i in range(window, len(scaled)):
        X.append(scaled[i-window:i, 0])
        y.append(scaled[i, 0])

    X = np.array(X).reshape(-1, window, 1)
    y = np.array(y)
    return X, y, scaler

client_X, client_y, client_scalers = {}, {}, {}

for cid, cdf in clients.items():
    X, y, scaler = create_timeseries(cdf["load"].values)
    client_X[cid] = X
    client_y[cid] = y
    client_scalers[cid] = scaler

# 4. Transformer Model
#=====================================================================
def transformer_encoder(inputs, num_heads=4, ff_dim=128):
    x = tf.keras.layers.LayerNormalization()(inputs)
    attn = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(x, x)
    x = tf.keras.layers.Add()([inputs, attn])

    ff = tf.keras.Sequential([
        tf.keras.layers.Dense(ff_dim, activation="relu"),
        tf.keras.layers.Dense(inputs.shape[-1])
    ])

    x_ff = ff(tf.keras.layers.LayerNormalization()(x))
    return tf.keras.layers.Add()([x, x_ff])


def build_model(window=24):
    inputs = tf.keras.Input(shape=(window, 1))
    x = tf.keras.layers.Dense(32)(inputs)
    x = transformer_encoder(x)
    x = transformer_encoder(x)
    x = tf.keras.layers.Flatten()(x)
    outputs = tf.keras.layers.Dense(1)(x)
    model = tf.keras.Model(inputs, outputs)
    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss="mae")
    return model

# 5. Manual Federated Averaging
#=====================================================================
def federated_avg(weights_list):
    new_weights = []
    for weights in zip(*weights_list):
        new_weights.append(np.mean(np.array(weights), axis=0))
    return new_weights

# 6. Federated Training Loop
#=====================================================================
ROUNDS = 10
global_model = build_model()

for rnd in range(1, ROUNDS + 1):
    client_weights = []

    for cid in clients.keys():
        model = build_model()
        model.set_weights(global_model.get_weights())  # sync with global

        model.fit(
            client_X[cid],
            client_y[cid],
            epochs=1,
            batch_size=32,
            verbose=0
        )

        client_weights.append(model.get_weights())

    # FedAvg aggregation
    new_global_weights = federated_avg(client_weights)
    global_model.set_weights(new_global_weights)

    print(f"Round {rnd}/{ROUNDS} completed.")

# 7. Predict Full Dataset
#=====================================================================
df_pred = df.copy()
df_pred["predicted_load"] = np.nan
WINDOW = 24

for cid, cdf in clients.items():
    X, _, scaler = create_timeseries(cdf["load"].values)
    preds = global_model.predict(X)
    preds_inv = scaler.inverse_transform(preds)

    rows = df_pred[df_pred["client_id"] == cid].index
    df_pred.loc[rows[WINDOW:], "predicted_load"] = preds_inv.squeeze()

df_pred.to_csv("federated_predictions.csv", index=False)
print("Saved: federated_predictions.csv")
print(df_pred.head())

import matplotlib.pyplot as plt

# 8. Plot Predicted vs Real (Per Client)
#=====================================================================
for cid in clients.keys():
    cdf = df_pred[df_pred["client_id"] == cid]

    plt.figure(figsize=(12, 4))
    plt.plot(cdf["datetime"], cdf["load"], label="Real Load", linewidth=2)
    plt.plot(cdf["datetime"], cdf["predicted_load"], label="Predicted Load", linestyle="--")

    plt.title(f"Predicted vs Real Load — {cid}")
    plt.xlabel("Datetime")
    plt.ylabel("Load")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(f"plot_{cid}.png")
    plt.show()

#=====================================================================
# 9. Combined Plot for Entire Dataset
#=====================================================================
plt.figure(figsize=(14, 5))
plt.plot(df_pred["datetime"], df_pred["load"], label="Real Load", linewidth=2)
plt.plot(df_pred["datetime"], df_pred["predicted_load"], label="Predicted Load", linestyle="--")

plt.title("Predicted vs Real Load (Global)")
plt.xlabel("Datetime")
plt.ylabel("Load")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("plot_global.png")
plt.show()

print("Saved client-wise and global plots.")

from sklearn.metrics import (
    mean_absolute_error,
    mean_squared_error,
    r2_score,
    f1_score,
    precision_score,
    recall_score,
    accuracy_score
)
import numpy as np

# Drop rows where prediction is NaN (first 24 hours per client)
df_eval = df_pred.dropna(subset=["predicted_load"]).copy()

y_true = df_eval["load"].values
y_pred = df_eval["predicted_load"].values

#=========================================================
# 1️⃣  REGRESSION METRICS (MAIN METRICS)
#=========================================================
def mape(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

MAE  = mean_absolute_error(y_true, y_pred)
MSE  = mean_squared_error(y_true, y_pred)
RMSE = np.sqrt(MSE)
R2   = r2_score(y_true, y_pred)
MAPE = mape(y_true, y_pred)

print("\n================= REGRESSION METRICS =================")
print(f"MAE  : {MAE:.4f}")
print(f"MSE  : {MSE:.4f}")
print(f"RMSE : {RMSE:.4f}")
print(f"R²   : {R2:.4f}")
print(f"MAPE : {MAPE:.2f}%")

#=========================================================
# SAVE GLOBAL MODEL
#=========================================================
global_model.save("global_transformer_model.h5")
print("Saved: global_transformer_model.h5")

import tensorflow as tf

# Load WITHOUT compiling!
global_model = tf.keras.models.load_model(
    "global_transformer_model.h5",
    compile=False
)

# Recompile manually
global_model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-3),
    loss=tf.keras.losses.MeanAbsoluteError()
)

print("Model loaded and recompiled successfully.")

import pandas as pd

df = pd.read_csv("federated_predictions.csv")
df["datetime"] = pd.to_datetime(df["datetime"])
df_pred = df.sort_values("datetime").reset_index(drop=True)

df_pred.head()